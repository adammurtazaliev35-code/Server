from flask import Flask, request, jsonify
import os
import requests
import json

app = Flask(__name__)

# Your existing SCENARIOS config (Keep it exactly as is)
SCENARIOS = {
    "general": {
        "name": "ðŸ’¬ ÐžÐ±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ñ‡Ð°Ñ‚",
        "temperature": 0.7,
        "max_tokens": 1024,
        "welcome_message": "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð¯ Ð²Ð°Ñˆ Ð˜Ð˜ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº...",
        "system_prompt": "Ð¢Ñ‹ - Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ AI Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ..."
    },
    # ... other scenarios ...
     "tech": {
        "name": "ðŸ”§ Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº", 
        "temperature": 0.3,
        "max_tokens": 2048,
        "welcome_message": "...",
        "system_prompt": "Ð¢Ñ‹ - Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÑÐºÑÐ¿ÐµÑ€Ñ‚..."
    },
    "creative": {
        "name": "ðŸŽ¨ ÐšÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼",
        "temperature": 0.9,
        "max_tokens": 1536,
        "welcome_message": "...",
        "system_prompt": "Ð¢Ñ‹ - ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð¿Ð¸ÑÐ°Ñ‚ÐµÐ»ÑŒ..."
    },
    "ideas": {
        "name": "ðŸ’¡ Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ð¸Ð´ÐµÐ¹",
        "temperature": 0.8,
        "max_tokens": 1024,
        "welcome_message": "...",
        "system_prompt": "Ð¢Ñ‹ - ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚ Ð¿Ð¾ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð´ÐµÐ¹..."
    }
}

def get_ai_response(history, scenario="general", temp_override=None, tokens_override=None):
    api_key = os.getenv("GEMINI_API_KEY")
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    
    config = SCENARIOS.get(scenario, SCENARIOS["general"])
    
    # LOGIC: Use slider value if provided, otherwise use default
    final_temp = float(temp_override) if temp_override is not None else config["temperature"]
    final_tokens = int(tokens_override) if tokens_override is not None else config["max_tokens"]

    # IMPROVEMENT: Use the official 'system_instruction' field
    payload = {
        "system_instruction": {
            "parts": [{"text": config["system_prompt"]}]
        },
        "contents": history, # We now pass the full history list
        "generationConfig": {
            "temperature": final_temp,
            "maxOutputTokens": final_tokens,
            "topP": 0.95,
            "topK": 40
        }
    }
    
    try:
        response = requests.post(url, json=payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        
        if "candidates" in result and len(result["candidates"]) > 0:
            return result["candidates"][0]["content"]["parts"][0]["text"]
        else:
            return "Error: No response from AI"
    except Exception as e:
        print(f"API Error: {e}")
        return f"Error connecting to AI: {str(e)}"

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.get_json()
    
    # The app can now send a 'history' array OR just a 'message'
    # If sending 'history', it should look like: 
    # [{"role": "user", "parts": [{"text": "Hi"}]}, {"role": "model", "parts": [{"text": "Hello"}]}]
    history = data.get('history', [])
    message = data.get('message', '')
    scenario = data.get('scenario', 'general')
    
    # Slider inputs
    temp = data.get('temperature')
    tokens = data.get('max_tokens')

    # If there is no history but there is a message, start a new history
    if not history and message:
        history = [{"role": "user", "parts": [{"text": message}]}]
    elif message:
        # Append current message to existing history
        history.append({"role": "user", "parts": [{"text": message}]})

    if not history:
         return jsonify({"error": "No message or history provided"}), 400

    # Commands logic (Optional: You can keep your command logic here if you want)
    
    ai_text = get_ai_response(history, scenario, temp, tokens)

    return jsonify({
        "response": ai_text,
        "scenario": scenario
    })

# ... Keep your other routes (welcome, scenarios, etc.) ...

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
