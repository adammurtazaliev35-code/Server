from flask import Flask, request, jsonify
import os
import requests
import json

app = Flask(__name__)

# --- CONFIGURATION ---
SCENARIOS = {
    "general": {
        "name": "üí¨ –û–±—ã—á–Ω—ã–π —á–∞—Ç",
        "temperature": 0.7,
        "max_tokens": 1024,
        "welcome_message": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø –≤–∞—à –ò–ò –ø–æ–º–æ—â–Ω–∏–∫...",
        "system_prompt": "–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –£ —Ç–µ–±—è –æ—Ç–ª–∏—á–Ω–∞—è –ø–∞–º—è—Ç—å, —Ç—ã –ø–æ–º–Ω–∏—à—å –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞—à–µ–π –±–µ—Å–µ–¥—ã. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
    },
    "tech": {
        "name": "üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫", 
        "temperature": 0.3,
        "max_tokens": 2048,
        "welcome_message": "–ì–æ—Ç–æ–≤ –∫ –æ—Ç–ª–∞–¥–∫–µ –∫–æ–¥–∞.",
        "system_prompt": "–¢—ã - —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —ç–∫—Å–ø–µ—Ä—Ç –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥, –∏—â–∏ –æ—à–∏–±–∫–∏ –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é."
    },
    "creative": {
        "name": "üé® –ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º",
        "temperature": 0.9,
        "max_tokens": 1536,
        "welcome_message": "–î–∞–≤–∞–π —Ç–≤–æ—Ä–∏—Ç—å!",
        "system_prompt": "–¢—ã - –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ø–∏—Å–∞—Ç–µ–ª—å. –ò—Å–ø–æ–ª—å–∑—É–π –±–æ–≥–∞—Ç—ã–π —è–∑—ã–∫, –º–µ—Ç–∞—Ñ–æ—Ä—ã –∏ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–¥–µ–∏."
    },
    "ideas": {
        "name": "üí° –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–¥–µ–π",
        "temperature": 0.8,
        "max_tokens": 1024,
        "welcome_message": "–ù—É–∂–Ω—ã –∏–¥–µ–∏?",
        "system_prompt": "–¢—ã - —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –º–æ–∑–≥–æ–≤–æ–º—É —à—Ç—É—Ä–º—É. –ü—Ä–µ–¥–ª–∞–≥–∞–π —Å–ø–∏—Å–∫–∏ –∏–¥–µ–π, –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏."
    }
}

def get_ai_response(history, scenario="general", temp_override=None, tokens_override=None):
    api_key = os.getenv("GEMINI_API_KEY")
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    
    config = SCENARIOS.get(scenario, SCENARIOS["general"])
    
    final_temp = float(temp_override) if temp_override is not None else config["temperature"]
    final_tokens = int(tokens_override) if tokens_override is not None else config["max_tokens"]

    payload = {
        "system_instruction": {
            "parts": [{"text": config["system_prompt"]}]
        },
        "contents": history, 
        "generationConfig": {
            "temperature": final_temp,
            "maxOutputTokens": final_tokens,
            "topP": 0.95,
            "topK": 40
        }
    }
    
    try:
        response = requests.post(url, json=payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        
        if "candidates" in result and len(result["candidates"]) > 0:
            return result["candidates"][0]["content"]["parts"][0]["text"]
        else:
            print(f"AI Error Response: {result}") # –õ–æ–≥ –æ—à–∏–±–∫–∏ –æ—Ç Google
            return "Error: Empty response from AI"
    except Exception as e:
        print(f"API Connection Error: {e}")
        return f"Error connecting to AI: {str(e)}"

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.get_json()
    
    # 1. –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    history = data.get('history', [])
    message = data.get('message', '')
    scenario = data.get('scenario', 'general')
    temp = data.get('temperature')
    tokens = data.get('max_tokens')

    # 2. –õ–û–ì–ò–†–û–í–ê–ù–ò–ï (–°–º–æ—Ç—Ä–∏ –≤ –∫–æ–Ω—Å–æ–ª—å —Å–µ—Ä–≤–µ—Ä–∞!)
    print(f"\n--- NEW REQUEST ---")
    print(f"Scenario: {scenario}")
    print(f"Received 'history' length: {len(history)}") # –°–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –ø—Ä–∏—à–ª–æ
    print(f"Received 'message': {message}")
    
    # 3. –õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    # –ï—Å–ª–∏ –ø—Ä–∏—à–µ–ª —Å–ø–∏—Å–æ–∫ history - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ.
    # –ï—Å–ª–∏ history –ø—É—Å—Ç–æ–π, –Ω–æ –µ—Å—Ç—å message (—Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è –∫–ª–∏–µ–Ω—Ç–∞) - —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å–ø–∏—Å–æ–∫.
    if not history and message:
        print("‚ö†Ô∏è WARNING: Using fallback (Message only mode)")
        history = [{"role": "user", "parts": [{"text": message}]}]
    elif message:
        # –ï—Å–ª–∏ –∑–∞—á–µ–º-—Ç–æ –ø—Ä–∏—Å–ª–∞–ª–∏ –∏ —Ç–æ –∏ —Ç–æ, –¥–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω–µ—Ü
        # –ù–æ —Ç–≤–æ–π –Ω–æ–≤—ã–π Android –∫–æ–¥ message –Ω–µ —à–ª–µ—Ç, —Ç–∞–∫ —á—Ç–æ —ç—Ç–æ—Ç –±–ª–æ–∫ –Ω–µ –¥–æ–ª–∂–µ–Ω —Å—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
        print("‚ö†Ô∏è Adding message to existing history")
        history.append({"role": "user", "parts": [{"text": message}]})

    if not history:
         return jsonify({"error": "No message or history provided"}), 400

    # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏: –≤—ã–≤–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ —É–π–¥–µ—Ç –≤ –ò–ò
    if len(history) > 0:
        print(f"Sending {len(history)} messages to Gemini. Last one: {history[-1]}")

    # 4. –ó–∞–ø—Ä–æ—Å
    ai_text = get_ai_response(history, scenario, temp, tokens)

    return jsonify({
        "response": ai_text,
        "scenario": scenario
    })

@app.route('/', methods=['GET'])
def home():
    return "AI Server is Running!"

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
